{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question : [nyc_weather.csv](https://github.com/codebasics/data-structures-algorithms-python/blob/master/data_structures/4_HashTable_2_Collisions/Solution/nyc_weather.csv) contains new york city weather for first few days in the month of January. Write a program that can answer following,\n",
    "    \n",
    "    1. What was the average temperature in first week of Jan?\n",
    "    2. What was the maximum temperature in first 10 days of Jan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_x_temperature={}\n",
    "with open('nyc_weather.csv','r') as f:\n",
    "    for line in f:\n",
    "        tokens=line.split(',')\n",
    "        date=tokens[0]\n",
    "        temperature=tokens[1]\n",
    "        date_x_temperature[date]=temperature\n",
    "del date_x_temperature['date'] # For removing 'date','temperature(F)' from the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date,temperature in date_x_temperature.items():\n",
    "    date_x_temperature[date]=float(temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Jan 1': 27.0,\n",
       " 'Jan 2': 31.0,\n",
       " 'Jan 3': 23.0,\n",
       " 'Jan 4': 34.0,\n",
       " 'Jan 5': 37.0,\n",
       " 'Jan 6': 38.0,\n",
       " 'Jan 7': 29.0,\n",
       " 'Jan 8': 30.0,\n",
       " 'Jan 9': 35.0,\n",
       " 'Jan 10': 30.0}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_x_temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What was the average temperature in first week of Jan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average temperature in first week of Jan is 31.2857\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "temperatures=[]\n",
    "dates=['Jan 1','Jan 2','Jan 3','Jan 4','Jan 5','Jan 6','Jan 7']\n",
    "for date in dates:\n",
    "    temperatures.append(date_x_temperature[date])\n",
    "print(f'The average temperature in first week of Jan is {np.mean(temperatures):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What was the maximum temperature in first 10 days of Jan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum temperature in first 10 days of Jan is 38.0\n"
     ]
    }
   ],
   "source": [
    "temperatures=[]\n",
    "for temperature in date_x_temperature.values():\n",
    "    temperatures.append(temperature)\n",
    "print(f'The maximum temperature in first 10 days of Jan is {max(temperatures)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best data structure to use here was a list because all we wanted was access of temperature elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature=[]\n",
    "with open('nyc_weather.csv','r') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            tokens=line.split(',')\n",
    "            temperature.append(float(tokens[1]))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[27.0, 31.0, 23.0, 34.0, 37.0, 38.0, 29.0, 30.0, 35.0, 30.0]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What was the average temperature in first week of Jan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average temperature in first week of Jan is 31.2857\n"
     ]
    }
   ],
   "source": [
    "average=sum(temperature[0:7])/len(temperature[0:7])\n",
    "print(f'The average temperature in first week of Jan is {average:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What was the maximum temperature in first 10 days of Jan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum temperature in first 10 days of Jan is 38.0\n"
     ]
    }
   ],
   "source": [
    "print(f'The maximum temperature in first 10 days of Jan is {max(temperature[0:10])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question : [nyc_weather.csv](https://github.com/codebasics/data-structures-algorithms-python/blob/master/data_structures/4_HashTable_2_Collisions/Solution/nyc_weather.csv) contains new york city weather for first few days in the month of January. Write a program that can answer following,\n",
    "\n",
    "    1. What was the temperature on Jan 9?\n",
    "    2. What was the temperature on Jan 4?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_x_temperature={}\n",
    "with open('nyc_weather.csv','r') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            tokens=line.split(',')\n",
    "            date=tokens[0]\n",
    "            temperature=float(tokens[1])\n",
    "            date_x_temperature[date]=temperature\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Jan 1': 27.0,\n",
       " 'Jan 2': 31.0,\n",
       " 'Jan 3': 23.0,\n",
       " 'Jan 4': 34.0,\n",
       " 'Jan 5': 37.0,\n",
       " 'Jan 6': 38.0,\n",
       " 'Jan 7': 29.0,\n",
       " 'Jan 8': 30.0,\n",
       " 'Jan 9': 35.0,\n",
       " 'Jan 10': 30.0}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_x_temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What was the temperature on Jan 9?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The temperature on Jan 9 is 35.0\n"
     ]
    }
   ],
   "source": [
    "print(f'The temperature on Jan 9 is {date_x_temperature['Jan 9']}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What was the temperature on Jan 4?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The temperature on Jan 4 is 34.0\n"
     ]
    }
   ],
   "source": [
    "print(f'The temperature on Jan 4 is {date_x_temperature['Jan 4']}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best data structure to use here was a dictionary (internally a hash table) because we wanted to know temperature for specific day, requiring key, value pair access where you can look up an element by day using O(1) complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question : [poem.txt](https://github.com/codebasics/data-structures-algorithms-python/blob/master/data_structures/4_HashTable_2_Collisions/Solution/poem.txt) Contains famous poem \"Road not taken\" by poet Robert Frost. You have to read this file in python and print every word and its count as show below. Think about the best data structure that you can use to solve this problem and figure out why you selected that specific data structure.\n",
    "```\n",
    " 'diverged': 2,\n",
    " 'in': 3,\n",
    " 'I': 8\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This in not the right code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "all_words=[]\n",
    "with open('poem.txt','r') as f:\n",
    "    for line in f:\n",
    "        words=re.findall(r'\\b\\w+\\b',line)\n",
    "        for word in words:\n",
    "            all_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Two',\n",
       " 'roads',\n",
       " 'diverged',\n",
       " 'in',\n",
       " 'a',\n",
       " 'yellow',\n",
       " 'wood',\n",
       " 'And',\n",
       " 'sorry',\n",
       " 'I',\n",
       " 'could',\n",
       " 'not',\n",
       " 'travel',\n",
       " 'both',\n",
       " 'And',\n",
       " 'be',\n",
       " 'one',\n",
       " 'traveler',\n",
       " 'long',\n",
       " 'I',\n",
       " 'stood',\n",
       " 'And',\n",
       " 'looked',\n",
       " 'down',\n",
       " 'one',\n",
       " 'as',\n",
       " 'far',\n",
       " 'as',\n",
       " 'I',\n",
       " 'could',\n",
       " 'To',\n",
       " 'where',\n",
       " 'it',\n",
       " 'bent',\n",
       " 'in',\n",
       " 'the',\n",
       " 'undergrowth',\n",
       " 'Then',\n",
       " 'took',\n",
       " 'the',\n",
       " 'other',\n",
       " 'as',\n",
       " 'just',\n",
       " 'as',\n",
       " 'fair',\n",
       " 'And',\n",
       " 'having',\n",
       " 'perhaps',\n",
       " 'the',\n",
       " 'better',\n",
       " 'claim',\n",
       " 'Because',\n",
       " 'it',\n",
       " 'was',\n",
       " 'grassy',\n",
       " 'and',\n",
       " 'wanted',\n",
       " 'wear',\n",
       " 'Though',\n",
       " 'as',\n",
       " 'for',\n",
       " 'that',\n",
       " 'the',\n",
       " 'passing',\n",
       " 'there',\n",
       " 'Had',\n",
       " 'worn',\n",
       " 'them',\n",
       " 'really',\n",
       " 'about',\n",
       " 'the',\n",
       " 'same',\n",
       " 'And',\n",
       " 'both',\n",
       " 'that',\n",
       " 'morning',\n",
       " 'equally',\n",
       " 'lay',\n",
       " 'In',\n",
       " 'leaves',\n",
       " 'no',\n",
       " 'step',\n",
       " 'had',\n",
       " 'trodden',\n",
       " 'black',\n",
       " 'Oh',\n",
       " 'I',\n",
       " 'kept',\n",
       " 'the',\n",
       " 'first',\n",
       " 'for',\n",
       " 'another',\n",
       " 'day',\n",
       " 'Yet',\n",
       " 'knowing',\n",
       " 'how',\n",
       " 'way',\n",
       " 'leads',\n",
       " 'on',\n",
       " 'to',\n",
       " 'way',\n",
       " 'I',\n",
       " 'doubted',\n",
       " 'if',\n",
       " 'I',\n",
       " 'should',\n",
       " 'ever',\n",
       " 'come',\n",
       " 'back',\n",
       " 'I',\n",
       " 'shall',\n",
       " 'be',\n",
       " 'telling',\n",
       " 'this',\n",
       " 'with',\n",
       " 'a',\n",
       " 'sigh',\n",
       " 'Somewhere',\n",
       " 'ages',\n",
       " 'and',\n",
       " 'ages',\n",
       " 'hence',\n",
       " 'Two',\n",
       " 'roads',\n",
       " 'diverged',\n",
       " 'in',\n",
       " 'a',\n",
       " 'wood',\n",
       " 'and',\n",
       " 'I',\n",
       " 'I',\n",
       " 'took',\n",
       " 'the',\n",
       " 'one',\n",
       " 'less',\n",
       " 'traveled',\n",
       " 'by',\n",
       " 'And',\n",
       " 'that',\n",
       " 'has',\n",
       " 'made',\n",
       " 'all',\n",
       " 'the',\n",
       " 'difference']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ord_of_words(words):\n",
    "    for word in words:\n",
    "        ord_sum=0\n",
    "        for letter in word:\n",
    "            ord_sum+=ord(letter)\n",
    "        print(f\"{word} : {ord_sum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two : 314\n",
      "roads : 537\n",
      "diverged : 842\n",
      "in : 215\n",
      "a : 97\n",
      "yellow : 668\n",
      "wood : 441\n",
      "And : 275\n",
      "sorry : 575\n",
      "I : 73\n",
      "could : 535\n",
      "not : 337\n",
      "travel : 654\n",
      "both : 429\n",
      "And : 275\n",
      "be : 199\n",
      "one : 322\n",
      "traveler : 869\n",
      "long : 432\n",
      "I : 73\n",
      "stood : 553\n",
      "And : 275\n",
      "looked : 638\n",
      "down : 440\n",
      "one : 322\n",
      "as : 212\n",
      "far : 313\n",
      "as : 212\n",
      "I : 73\n",
      "could : 535\n",
      "To : 195\n",
      "where : 539\n",
      "it : 221\n",
      "bent : 425\n",
      "in : 215\n",
      "the : 321\n",
      "undergrowth : 1209\n",
      "Then : 399\n",
      "took : 445\n",
      "the : 321\n",
      "other : 546\n",
      "as : 212\n",
      "just : 454\n",
      "as : 212\n",
      "fair : 418\n",
      "And : 275\n",
      "having : 637\n",
      "perhaps : 755\n",
      "the : 321\n",
      "better : 646\n",
      "claim : 518\n",
      "Because : 696\n",
      "it : 221\n",
      "was : 331\n",
      "grassy : 665\n",
      "and : 307\n",
      "wanted : 643\n",
      "wear : 431\n",
      "Though : 623\n",
      "as : 212\n",
      "for : 327\n",
      "that : 433\n",
      "the : 321\n",
      "passing : 757\n",
      "there : 536\n",
      "Had : 269\n",
      "worn : 454\n",
      "them : 430\n",
      "really : 649\n",
      "about : 539\n",
      "the : 321\n",
      "same : 422\n",
      "And : 275\n",
      "both : 429\n",
      "that : 433\n",
      "morning : 762\n",
      "equally : 765\n",
      "lay : 326\n",
      "In : 183\n",
      "leaves : 640\n",
      "no : 221\n",
      "step : 444\n",
      "had : 301\n",
      "trodden : 752\n",
      "black : 509\n",
      "Oh : 183\n",
      "I : 73\n",
      "kept : 436\n",
      "the : 321\n",
      "first : 552\n",
      "for : 327\n",
      "another : 753\n",
      "day : 318\n",
      "Yet : 306\n",
      "knowing : 765\n",
      "how : 334\n",
      "way : 337\n",
      "leads : 521\n",
      "on : 221\n",
      "to : 227\n",
      "way : 337\n",
      "I : 73\n",
      "doubted : 743\n",
      "if : 207\n",
      "I : 73\n",
      "should : 655\n",
      "ever : 434\n",
      "come : 420\n",
      "back : 401\n",
      "I : 73\n",
      "shall : 532\n",
      "be : 199\n",
      "telling : 751\n",
      "this : 440\n",
      "with : 444\n",
      "a : 97\n",
      "sigh : 427\n",
      "Somewhere : 943\n",
      "ages : 416\n",
      "and : 307\n",
      "ages : 416\n",
      "hence : 515\n",
      "Two : 314\n",
      "roads : 537\n",
      "diverged : 842\n",
      "in : 215\n",
      "a : 97\n",
      "wood : 441\n",
      "and : 307\n",
      "I : 73\n",
      "I : 73\n",
      "took : 445\n",
      "the : 321\n",
      "one : 322\n",
      "less : 439\n",
      "traveled : 855\n",
      "by : 219\n",
      "And : 275\n",
      "that : 433\n",
      "has : 316\n",
      "made : 407\n",
      "all : 313\n",
      "the : 321\n",
      "difference : 1035\n"
     ]
    }
   ],
   "source": [
    "ord_of_words(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The right code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict={}\n",
    "with open('poem.txt','r') as f:\n",
    "    for line in f:\n",
    "        tokens=line.split(' ')\n",
    "        for token in tokens:\n",
    "            token=token.replace('\\n','')\n",
    "            if token in word_dict:\n",
    "                word_dict[token]+=1\n",
    "            else:\n",
    "                word_dict[token]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Two': 2,\n",
       " 'roads': 2,\n",
       " 'diverged': 2,\n",
       " 'in': 3,\n",
       " 'a': 3,\n",
       " 'yellow': 1,\n",
       " 'wood,': 2,\n",
       " 'And': 6,\n",
       " 'sorry': 1,\n",
       " 'I': 8,\n",
       " 'could': 2,\n",
       " 'not': 1,\n",
       " 'travel': 1,\n",
       " 'both': 2,\n",
       " 'be': 2,\n",
       " 'one': 3,\n",
       " 'traveler,': 1,\n",
       " 'long': 1,\n",
       " 'stood': 1,\n",
       " 'looked': 1,\n",
       " 'down': 1,\n",
       " 'as': 5,\n",
       " 'far': 1,\n",
       " 'To': 1,\n",
       " 'where': 1,\n",
       " 'it': 2,\n",
       " 'bent': 1,\n",
       " 'the': 8,\n",
       " 'undergrowth;': 1,\n",
       " '': 3,\n",
       " 'Then': 1,\n",
       " 'took': 2,\n",
       " 'other,': 1,\n",
       " 'just': 1,\n",
       " 'fair,': 1,\n",
       " 'having': 1,\n",
       " 'perhaps': 1,\n",
       " 'better': 1,\n",
       " 'claim,': 1,\n",
       " 'Because': 1,\n",
       " 'was': 1,\n",
       " 'grassy': 1,\n",
       " 'and': 3,\n",
       " 'wanted': 1,\n",
       " 'wear;': 1,\n",
       " 'Though': 1,\n",
       " 'for': 2,\n",
       " 'that': 3,\n",
       " 'passing': 1,\n",
       " 'there': 1,\n",
       " 'Had': 1,\n",
       " 'worn': 1,\n",
       " 'them': 1,\n",
       " 'really': 1,\n",
       " 'about': 1,\n",
       " 'same,': 1,\n",
       " 'morning': 1,\n",
       " 'equally': 1,\n",
       " 'lay': 1,\n",
       " 'In': 1,\n",
       " 'leaves': 1,\n",
       " 'no': 1,\n",
       " 'step': 1,\n",
       " 'had': 1,\n",
       " 'trodden': 1,\n",
       " 'black.': 1,\n",
       " 'Oh,': 1,\n",
       " 'kept': 1,\n",
       " 'first': 1,\n",
       " 'another': 1,\n",
       " 'day!': 1,\n",
       " 'Yet': 1,\n",
       " 'knowing': 1,\n",
       " 'how': 1,\n",
       " 'way': 1,\n",
       " 'leads': 1,\n",
       " 'on': 1,\n",
       " 'to': 1,\n",
       " 'way,': 1,\n",
       " 'doubted': 1,\n",
       " 'if': 1,\n",
       " 'should': 1,\n",
       " 'ever': 1,\n",
       " 'come': 1,\n",
       " 'back.': 1,\n",
       " 'shall': 1,\n",
       " 'telling': 1,\n",
       " 'this': 1,\n",
       " 'with': 1,\n",
       " 'sigh': 1,\n",
       " 'Somewhere': 1,\n",
       " 'ages': 2,\n",
       " 'hence:': 1,\n",
       " 'I—': 1,\n",
       " 'less': 1,\n",
       " 'traveled': 1,\n",
       " 'by,': 1,\n",
       " 'has': 1,\n",
       " 'made': 1,\n",
       " 'all': 1,\n",
       " 'difference.': 1}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question : Implement hash table where collisions are handled using linear probing. We learnt about linear probing in the video tutorial. Take the hash table implementation that uses chaining and modify methods to use **linear probing**. Keep MAX size of arr in hashtable as 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question : Implement hash table where collisions are handled using linear probing. We learnt about linear probing in the video tutorial. Take the hash table implementation that uses chaining and modify methods to use **linear probing**. Keep MAX size of arr in hashtable as 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hash_Table:\n",
    "    def __init__(self):\n",
    "        self.Max=10\n",
    "        self.array=[[] for i in range(self.Max)]\n",
    "    def get_hash(self,key):\n",
    "        count=0\n",
    "        for char in key:\n",
    "            count+=ord(char)\n",
    "        return count % self.Max\n",
    "    def __setitem__(self,key,val):\n",
    "        h=self.get_hash(key)\n",
    "        found=False\n",
    "        for idx,element in enumerate(self.array[h]):\n",
    "            if len(element)==2 and element[0]==key:\n",
    "                self.array[h][idx]=(key,val)  \n",
    "        if not found:\n",
    "            self.array[h].append((key,val))\n",
    "    def __getitem__(self,key):\n",
    "        h=self.get_hash(key)\n",
    "        for element in self.array[h]:\n",
    "            if element[0]==key:\n",
    "                return element[1]\n",
    "    def __delitem__(self,key):\n",
    "        h=self.get_hash(key)\n",
    "        for idx,element in enumerate(self.array[h]):\n",
    "            if element[0]==key:\n",
    "                del self.array[h][idx]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash=Hash_Table()\n",
    "hash.get_hash('Arpon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash['Arpon'] = 190\n",
    "hash['arpon'] = 1945\n",
    "hash['pon'] = 1\n",
    "hash['example'] = 763\n",
    "hash['HashMap'] = 821\n",
    "hash['Python'] = 109\n",
    "hash['variable'] = 403\n",
    "hash['function'] = 78\n",
    "hash['loop'] = 670\n",
    "hash['data'] = 212\n",
    "hash['structure'] = 900\n",
    "hash['key'] = 567\n",
    "hash['value'] = 345\n",
    "hash['compute'] = 432\n",
    "hash['algorithm'] = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('function', 78), ('data', 212)],\n",
       " [('value', 345)],\n",
       " [('Arpon', 190), ('Python', 109), ('loop', 670)],\n",
       " [('pon', 1)],\n",
       " [('arpon', 1945), ('HashMap', 821)],\n",
       " [('compute', 432)],\n",
       " [],\n",
       " [('algorithm', 256)],\n",
       " [('example', 763), ('variable', 403)],\n",
       " [('structure', 900), ('key', 567)]]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving elements:\n",
      "hash['Arpon']: 190\n",
      "hash['loop']: 670\n"
     ]
    }
   ],
   "source": [
    "print(\"Retrieving elements:\")\n",
    "print(\"hash['Arpon']:\", hash['Arpon'])\n",
    "print(\"hash['loop']:\", hash['loop'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update an Element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated hash['loop'] to 999:\n",
      "hash['loop']: 999\n"
     ]
    }
   ],
   "source": [
    "hash['loop'] = 999\n",
    "print(\"Updated hash['loop'] to 999:\")\n",
    "print(\"hash['loop']:\", hash['loop'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete an Element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted hash['loop']\n",
      "Current hash table state after deleting 'loop':\n",
      "[[('function', 78), ('data', 212)], [('value', 345)], [('Arpon', 190), ('Python', 109), ('loop', 999)], [('pon', 1)], [('arpon', 1945), ('HashMap', 821)], [('compute', 432)], [], [('algorithm', 256)], [('example', 763), ('variable', 403)], [('structure', 900), ('key', 567)]]\n"
     ]
    }
   ],
   "source": [
    "del hash['loop']\n",
    "print(\"Deleted hash['loop']\")\n",
    "print(\"Current hash table state after deleting 'loop':\")\n",
    "print(hash.array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to Retrieve a Deleted Element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash['loop']: 999\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"hash['loop']:\", hash['loop'])\n",
    "except KeyError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert Elements to Cause Collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash table state after handling collisions:\n",
      "[[('function', 78), ('data', 212)], [('value', 345), ('value', 345)], [('Arpon', 190), ('Python', 109), ('loop', 999)], [('pon', 1)], [('arpon', 1945), ('HashMap', 821)], [('compute', 432), ('compute', 432)], [], [('algorithm', 256), ('algorithm', 256)], [('example', 763), ('variable', 403)], [('structure', 900), ('key', 567)]]\n"
     ]
    }
   ],
   "source": [
    "hash['compute'] = 432\n",
    "hash['algorithm'] = 256\n",
    "hash['value'] = 345\n",
    "print(\"Hash table state after handling collisions:\")\n",
    "print(hash.array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Full Hash Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    hash['extra'] = 100\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
